---
- name: Ensure command line variables are set
  gather_facts: False
  hosts: 127.0.0.1
  connection: local
  tasks:
    - assert:
        that:
          - current_master is defined
          - instance is defined
          - current_slave is defined
          - cross_dc_slave is defined

- name: Get slave IP
  gather_facts: False
  become: true
  hosts:
    - '{{ current_slave }}'
  tasks:
    - name: get IP slave
      shell: ifconfig lagg0 | grep 'inet' | awk -F ' ' '{ print $2 }'
      register: current_slave_ip
#    - debug: var=current_slave_ip.stdout

- name: Get cross dc slave IP
  gather_facts: False
  become: true
  hosts:
    - '{{ cross_dc_slave }}'
  tasks:
    - name: get IP slave
      shell: ifconfig lagg0 | grep 'inet' | awk -F ' ' '{ print $2 }'
      register: current_cross_dc_slave_ip
#    - debug: var=current_cross_dc_slave_ip.stdout


- name: Get same dc slave IP
  gather_facts: False
  become: true
  hosts:
    - '{{ same_dc_slave }}'
  tasks:
    - name: get IP slave
      shell: ifconfig lagg0 | grep 'inet' | awk -F ' ' '{ print $2 }'
      register: current_same_dc_slave_ip
#    - debug: var=current_same_dc_slave_ip.stdout

- name: Master checks
  gather_facts: False
  become: true
  hosts: 
    - '{{ current_master }}'
  tasks:
    - set_fact: my_slave_ip={{ hostvars[current_slave]['current_slave_ip']['stdout'] }}
#    - debug: var=my_slave_ip

    - name: get IP master
      shell: ifconfig lagg0 | grep 'inet' | awk -F ' ' '{ print $2 }'
      register: current_master_ip
#    - debug: var=current_master_ip.stdout

    - name: Copy check
      copy:
        src: ../../roles/check_mk/files/checks/postgresql/check_db_postgres_vip_generic
        dest: "/var/groupon/check_mk/checks/"
        owner: root
        group: wheel
        mode: 0655
    - name: Copy local
      copy:
        src: ../../roles/check_mk/files/locals/postgresql/common/postgres_db_vip_generic.sh
        dest: "/usr/lib/check_mk_agent/local/120/"
        owner: root
        group: wheel
        mode: 0655

    - name: Confirm rw_vip is on the master
      shell: /var/groupon/check_mk/checks/check_db_postgres_vip_generic -v {{ gds_instances[instance].master_vip }} -p {{ gds_instances[instance].ports.postgresql_raw }} -w 50 -c 100 | grep 'OK - VIP is OK'
      register: rw_vip_on_master
#    - debug: var=rw_vip_on_master.stdout
    - name: verify the rw vip is on the master
      fail: msg="Exiting ----------rw VIP is not on the master"
      when:  rw_vip_on_master.stdout  ==  ""


    - name: Confirm master is not in recovery
      command: psql -U postgres -A -t -d {{ gds_instances[instance].dbnames.0 }} -p {{ gds_instances[instance].ports.postgresql_raw }} -c "select pg_is_in_recovery()"
      register: it_is_in_recovery
#    - debug: var=it_is_in_recovery.stdout
    - name: verify it's the master
      fail: msg="Exiting ----------It is not a master database"
      when:  it_is_in_recovery.stdout  ==  "t"


    - name: Find if slave exists
      command: psql -U postgres -A -t -d {{ gds_instances[instance].dbnames.0 }} -p {{ gds_instances[instance].ports.postgresql_raw }} -c "select client_addr from pg_stat_replication where client_addr='{{ my_slave_ip }}'"
      register: slave_ip
#    - debug: var=slave_ip.stdout
    - name: verify slave exists
      fail: msg="Exiting ----------Slave does not exist"
      when:  slave_ip.stdout == ""

    - name: Replication lag
      command: psql -U postgres -A -t -d {{ gds_instances[instance].dbnames.0 }} -p {{ gds_instances[instance].ports.postgresql_raw }} -c "select pg_xlog_location_diff(pg_current_xlog_location(),write_location)  from pg_stat_replication where client_addr='{{ my_slave_ip }}'"
      register: replication_lag
      until: replication_lag.stdout|int < 100000000
      retries: 1000
      delay: 1
#    - debug: var=replication_lag.stdout

    - name: Copy check
      copy:
        src: ../../roles/check_mk/files/checks/postgresql/check_db_data_dir
        dest: "/var/groupon/check_mk/checks/"
        owner: root
        group: wheel
        mode: 0655
    - name: Copy local
      copy:
        src: ../../roles/check_mk/files/locals/postgresql/common/postgres_db_data_dir.sh
        dest: "/usr/lib/check_mk_agent/local/120/"
        owner: root
        group: wheel
        mode: 0655

    - name: Find if instance name is correct
      shell: /var/groupon/check_mk/checks/check_db_data_dir -i {{ instance }} -p {{ gds_instances[instance].ports.postgresql_raw }} -w 50 -c 100 | grep 'OK - Data Directory is OK'
      register: instance_is_correct
#    - debug: var=instance_is_correct.stdout
    - name: verify it is the correct instance name
      fail: msg="Exiting ----------Instance name is not the correct one"
      when:  instance_is_correct.stdout  ==  ""


- name: Slave checks
  gather_facts: False
  become: true
  hosts:
    - '{{ current_slave }}'
  tasks:
    - name: Confirm it's in recovery
      command: psql -U postgres -A -t -d {{ gds_instances[instance].dbnames.0 }} -p {{ gds_instances[instance].ports.postgresql_raw }} -c "select pg_is_in_recovery()"
      register: it_is_in_recovery_slave
#    - debug: var=it_is_in_recovery_slave.stdout
    - name: verify if it's the slave
      fail: msg="Exiting ----------It is not a slave database"
      when:  it_is_in_recovery_slave.stdout  ==  "f"

    - name: Copy check
      copy:
        src: ../../roles/check_mk/files/checks/postgresql/check_db_postgres_vip_generic
        dest: "/var/groupon/check_mk/checks/"
        owner: root
        group: wheel
        mode: 0655
    - name: Copy local
      copy:
        src: ../../roles/check_mk/files/locals/postgresql/common/postgres_db_vip_generic.sh
        dest: "/usr/lib/check_mk_agent/local/120/"
        owner: root
        group: wheel
        mode: 0655

    - name: Confirm cross dc rw_vip is on the slave
      shell: /var/groupon/check_mk/checks/check_db_postgres_vip_generic -v {{ gds_instances[instance].master_vip }} -p {{ gds_instances[instance].ports.postgresql_raw }} -w 50 -c 100 | grep 'OK - VIP is OK'
      register: rw_crossdc_vip_on_slave
#    - debug: var=rw_crossdc_vip_on_slave.stdout
    - name: verify the rw crossdc vip is on the slave
      fail: msg="Exiting ----------cross dc rw VIP is not on the slave"
      when:  rw_crossdc_vip_on_slave.stdout  ==  ""

    - name: Copy check
      copy:
        src: ../../roles/check_mk/files/checks/postgresql/check_db_data_dir
        dest: "/var/groupon/check_mk/checks/"
        owner: root
        group: wheel
        mode: 0655
    - name: Copy local
      copy:
        src: ../../roles/check_mk/files/locals/postgresql/common/postgres_db_data_dir.sh
        dest: "/usr/lib/check_mk_agent/local/120/"
        owner: root
        group: wheel
        mode: 0655

    - name: Find if instance name is correct
      shell: /var/groupon/check_mk/checks/check_db_data_dir -i {{ instance }} -p {{ gds_instances[instance].ports.postgresql_raw }} -w 50 -c 100 | grep 'OK - Data Directory is OK'
      register: instance_is_correct
#    - debug: var=instance_is_correct.stdout
    - name: verify it is the correct instance name
      fail: msg="Exiting ----------Instance name is not the correct one"
      when:  instance_is_correct.stdout  ==  ""

- name: Master changes
  gather_facts: False
  become: true
  hosts:
    - '{{ current_master }}'
  tasks:
    - pause: prompt="Are you sure you want to proceed with the failover? Press ENTER to continue..."

    - set_fact: my_slave_ip={{ hostvars[current_slave]['current_slave_ip']['stdout'] }}
#    - debug: var=my_slave_ip

    - name: Checkpoint on master to make the shutdown faster
      command: psql -U postgres -A -t -d {{ gds_instances[instance].dbnames.0 }} -p {{ gds_instances[instance].ports.postgresql_raw }} -c "checkpoint"

    - name: Do not allow connections to this database anymore
      command: psql -U postgres -A -t -d {{ gds_instances[instance].dbnames.0 }} -p {{ gds_instances[instance].ports.postgresql_raw }} -c "update pg_database set datallowconn='f' where datname='{{ gds_instances[instance].dbnames.0 }}'"

    - name: Kill all sessions
      command: psql -U postgres -A -t -d postgres -p {{ gds_instances[instance].ports.postgresql_raw }} -c "select pg_terminate_backend(pid) from pg_stat_activity where pid != pg_backend_pid()"

    - name: Everything has reached the slave
      command: psql -U postgres -A -t -d postgres -p {{ gds_instances[instance].ports.postgresql_raw }} -c "select pg_xlog_location_diff(pg_current_xlog_location(),write_location) from pg_stat_replication where client_addr='{{ my_slave_ip }}'"
      register: replication_lag_final
      until: replication_lag_final.stdout == "0"
      retries: 1000
      delay: 1
#    - debug: var=replication_lag_final.stdout

    - name: Shutdown the instance
      shell: sv down /var/service/postgresql-{{ gds_cluster }}-{{ instance }}/ && sv int /var/service/postgresql-{{ gds_cluster }}-{{ instance }}/

    - name: Find if pid still exists
      stat: path=/var/groupon/postgresql/data94/{{ gds_cluster }}-{{ instance }}/data/postmaster.pid
      register: is_postmaster_online
      until: is_postmaster_online.stat.exists == False
      retries: 300
      delay: 1
#    - debug: var=is_postmaster_online.stat.exists

    - name: Extract latest checkpoint location for the master
      shell: pg_controldata /var/groupon/postgresql/data94/{{ gds_cluster }}-{{ instance }}/data | grep 'Latest checkpoint location:' | awk '{print $4}'
      register: latest_chkpt_loc_master
#    - debug: var=latest_chkpt_loc_master.stdout


- name: Slave changes
  gather_facts: False
  become: true
  hosts:
    - '{{ current_slave }}'
  tasks:
#    - set_fact: my_unix_user={{ gds_instances[instance].unix_user }}

    - name: Kill all sessions
      command: psql -U postgres -A -t -d postgres -p {{ gds_instances[instance].ports.postgresql_raw }} -c "select pg_terminate_backend(pid) from pg_stat_activity where pid != pg_backend_pid()"

    - name: Checkpoint on slave to make the startup faster
      command: psql -U postgres -A -t -d postgres -p {{ gds_instances[instance].ports.postgresql_raw }} -c "checkpoint"

    - name: Everything has been applied on the slave
      command: psql -U postgres -A -t -d postgres -p {{ gds_instances[instance].ports.postgresql_raw }} -c "select pg_xlog_location_diff(pg_last_xlog_receive_location(),pg_last_xlog_replay_location())"
      register: replication_lag_final2
      until: replication_lag_final2.stdout == "0"
      retries: 1000
      delay: 1
#    - debug: var=replication_lag_final2.stdout

    - name: Checkpoint on slave to make the startup faster2
      command: psql -U postgres -A -t -d postgres -p {{ gds_instances[instance].ports.postgresql_raw }} -c "checkpoint"

    - name: Extract latest checkpoint location for the slave
      shell: pg_controldata /var/groupon/postgresql/data94/{{ gds_cluster }}-{{ instance }}/data | grep 'Latest checkpoint location:' | awk '{print $4}'
      register: latest_chkpt_loc_slave
      until: latest_chkpt_loc_slave.stdout == hostvars[current_master]['latest_chkpt_loc_master']['stdout'] 
      retries: 300
      delay: 1
#    - debug: var=latest_chkpt_loc_slave.stdout

    - name: Promote the slave
      shell: su -m {{ gds_instances[instance].unix_user }} -c "pg_ctl promote -D /var/groupon/postgresql/data94/{{ gds_cluster }}-{{ instance }}/data"

    - name: Confirm it's not in recovery
      command: psql -U postgres -A -t -d postgres -p {{ gds_instances[instance].ports.postgresql_raw }} -c "select pg_is_in_recovery()"
      register: it_is_in_recovery_final
      until: it_is_in_recovery_final.stdout == "f"
      retries: 300
      delay: 1
#    - debug: var=it_is_in_recovery_final.stdout

    - name: Allow connections to this database
      command: psql -U postgres -A -t -d postgres -p {{ gds_instances[instance].ports.postgresql_raw }} -c "update pg_database set datallowconn='t' where datname='{{ gds_instances[instance].dbnames.0 }}'"


- name: Final master changes
  gather_facts: False
  become: true
  hosts:
    - '{{ current_master }}'
  tasks:
    - name: check if recovery.conf exists on the former master
      stat: path=/var/groupon/postgresql/data94/{{ gds_cluster }}-{{ instance }}/data/recovery.conf
      register: recov_conf
#    - debug: var=recov_conf.stat.exists

    - name: create recovery.conf if it's not there already
 #     shell: touch /var/groupon/postgresql/data94/{{ gds_cluster }}-{{ instance }}/data/recovery.conf
      file: path=/var/groupon/postgresql/data94/{{ gds_cluster }}-{{ instance }}/data/recovery.conf state=touch owner={{ gds_instances[instance].unix_user }} group=ops_gds_app mode=0600
      when: recov_conf.stat.exists == False

    - name: set parameters in the recovery.conf
      lineinfile:
        dest: "/var/groupon/postgresql/data94/{{ gds_cluster }}-{{ instance }}/data/recovery.conf"
        regexp: "{{ item.regexp }}"
        line: "{{ item.line }}"
      with_items:
        - { regexp: "^standby_mode", line: "standby_mode = 'on'" }
        - { regexp: "^primary_conninfo", line: "primary_conninfo = 'user=postgres host={{ hostvars[current_master]['slave_ip']['stdout'] }} port={{ gds_instances[instance].ports.postgresql_raw }} sslmode=prefer sslcompression=1'" }
        - { regexp: "^recovery_target_timeline", line: "recovery_target_timeline = 'latest'" }

#    - name: set chown on recovery.conf
#      shell: chown {{ gds_instances[instance].unix_user }}:ops_gds_app /var/groupon/postgresql/data94/{{ gds_cluster }}-{{ instance }}/data/recovery.conf
#
#    - name: set chmod on recovery.conf
#      shell: chmod 0600 /var/groupon/postgresql/data94/{{ gds_cluster }}-{{ instance }}/data/recovery.conf

    - name: Startup the instance
      shell: sv start /var/service/postgresql-{{ gds_cluster }}-{{ instance }}/

    - name: Find if pid was created
      stat: path=/var/groupon/postgresql/data94/{{ gds_cluster }}-{{ instance }}/data/postmaster.pid
      register: is_postmaster_back_online
      until: is_postmaster_back_online.stat.exists == True
      retries: 300
      delay: 1
#    - debug: var=is_postmaster_back_online.stat.exists

- name: Cross dc slave changes
  gather_facts: False
  become: true
  hosts:
    - '{{ cross_dc_slave }}'
  tasks:
    - name: Confirm it's in recovery
      command: psql -U postgres -A -t -d {{ gds_instances[instance].dbnames.0 }} -p {{ gds_instances[instance].ports.postgresql_raw }} -c "select pg_is_in_recovery()"
      register: it_is_in_recovery_slave
#    - debug: var=it_is_in_recovery_slave.stdout
    - name: verify if it's the slave
      fail: msg="Exiting ----------It is not a slave database"
      when:  it_is_in_recovery_slave.stdout  ==  "f"

    - name: Copy check
      copy:
        src: ../../roles/check_mk/files/checks/postgresql/check_db_data_dir
        dest: "/var/groupon/check_mk/checks/"
        owner: root
        group: wheel
        mode: 0655
    - name: Copy local
      copy:
        src: ../../roles/check_mk/files/locals/postgresql/common/postgres_db_data_dir.sh
        dest: "/usr/lib/check_mk_agent/local/120/"
        owner: root
        group: wheel
        mode: 0655

    - name: Find if instance name is correct
      shell: /var/groupon/check_mk/checks/check_db_data_dir -i {{ instance }} -p {{ gds_instances[instance].ports.postgresql_raw }} -w 50 -c 100 | grep 'OK - Data Directory is OK'
      register: instance_crossdc_is_correct
#    - debug: var=instance_crossdc_is_correct.stdout
    - name: verify it is the correct instance name
      fail: msg="Exiting ----------Instance name is not the correct one"
      when:  instance_crossdc_is_correct.stdout  ==  ""

    - name: Replication lag
      command: psql -U postgres -A -t -p {{ gds_instances[instance].ports.postgresql_raw }} -c "select pg_xlog_location_diff(pg_last_xlog_receive_location(),pg_last_xlog_replay_location())"
      register: crossdc_replication_lag
      until: crossdc_replication_lag.stdout|int < 10000000
      retries: 1000
      delay: 1

    - name: Confirm streaming replication is ok
      shell: /var/groupon/check_mk/checks/check_db_last_wal -w 600 -c 10800 -p {{ gds_instances[instance].ports.postgresql_raw }} | grep 'OK - Streaming replication is ok'
      register: streaming_repl_crossdc
#    - debug: var=streaming_repl_crossdc.stdout
    - name: verify streaming replication is ok
      fail: msg="Exiting ----------streaming replication is not ok"
      when:  streaming_repl_crossdc.stdout  ==  ""

    - name: Kill all sessions
      command: psql -U postgres -A -t -d postgres -p {{ gds_instances[instance].ports.postgresql_raw }} -c "select pg_terminate_backend(pid) from pg_stat_activity where pid != pg_backend_pid()"

    - name: Checkpoint on crossdc slave to make the restart faster
      command: psql -U postgres -A -t -d {{ gds_instances[instance].dbnames.0 }} -p {{ gds_instances[instance].ports.postgresql_raw }} -c "checkpoint"

    - name: set new IP in the recovery.conf
      lineinfile:
        dest: "/var/groupon/postgresql/data94/{{ gds_cluster }}-{{ instance }}/data/recovery.conf"
        regexp: "{{ item.regexp }}"
        line: "{{ item.line }}"
      with_items:
        - { regexp: "^primary_conninfo", line: "primary_conninfo = 'user=postgres host={{ hostvars[current_master]['slave_ip']['stdout'] }} port={{ gds_instances[instance].ports.postgresql_raw }} sslmode=prefer sslcompression=1'" }
        - { regexp: "^recovery_target_timeline", line: "recovery_target_timeline = 'latest'" }

    - name: Restart the instance
      shell: sv int /var/service/postgresql-{{ gds_cluster }}-{{ instance }}/


- name: Same dc slave changes
  gather_facts: False
  become: true
  hosts:
    - '{{ same_dc_slave }}'
  tasks:
    - set_fact: my_crossdc_slave_ip={{ hostvars[cross_dc_slave]['current_cross_dc_slave_ip']['stdout'] }}
#    - debug: var=my_crossdc_slave_ip

    - name: Confirm it's in recovery
      command: psql -U postgres -A -t -d {{ gds_instances[instance].dbnames.0 }} -p {{ gds_instances[instance].ports.postgresql_raw }} -c "select pg_is_in_recovery()"
      register: it_is_in_recovery_slave
#    - debug: var=it_is_in_recovery_slave.stdout
    - name: verify if it's the slave
      fail: msg="Exiting ----------It is not a slave database"
      when:  it_is_in_recovery_slave.stdout  ==  "f"

    - name: Copy check
      copy:
        src: ../../roles/check_mk/files/checks/postgresql/check_db_data_dir
        dest: "/var/groupon/check_mk/checks/"
        owner: root
        group: wheel
        mode: 0655

    - name: Copy local
      copy:
        src: ../../roles/check_mk/files/locals/postgresql/common/postgres_db_data_dir.sh
        dest: "/usr/lib/check_mk_agent/local/120/"
        owner: root
        group: wheel
        mode: 0655

    - name: Find if instance name is correct
      shell: /var/groupon/check_mk/checks/check_db_data_dir -i {{ instance }} -p {{ gds_instances[instance].ports.postgresql_raw }} -w 50 -c 100 | grep 'OK - Data Directory is OK'
      register: instance_crossdc_is_correct
#    - debug: var=instance_crossdc_is_correct.stdout
    - name: verify it is the correct instance name
      fail: msg="Exiting ----------Instance name is not the correct one"
      when:  instance_crossdc_is_correct.stdout  ==  "" 

    - name: Replication lag
      command: psql -U postgres -A -t -p {{ gds_instances[instance].ports.postgresql_raw }} -c "select pg_xlog_location_diff(pg_last_xlog_receive_location(),pg_last_xlog_replay_location())"
      register: crossdc_replication_lag
      until: crossdc_replication_lag.stdout|int < 10000000
      retries: 1000
      delay: 1

    - name: Confirm streaming replication is ok
      shell: /var/groupon/check_mk/checks/check_db_last_wal -w 600 -c 10800 -p {{ gds_instances[instance].ports.postgresql_raw }} | grep 'OK - Streaming replication is ok'
      register: streaming_repl_crossdc
#    - debug: var=streaming_repl_crossdc.stdout
    - name: verify streaming replication is ok
      fail: msg="Exiting ----------streaming replication is not ok"
      when:  streaming_repl_crossdc.stdout  ==  ""

    - name: Kill all sessions
      command: psql -U postgres -A -t -d postgres -p {{ gds_instances[instance].ports.postgresql_raw }} -c "select pg_terminate_backend(pid) from pg_stat_activity where pid != pg_backend_pid()"

    - name: Checkpoint on samedc slave to make the restart faster
      command: psql -U postgres -A -t -d {{ gds_instances[instance].dbnames.0 }} -p {{ gds_instances[instance].ports.postgresql_raw }} -c "checkpoint"

    - name: set new IP in the recovery.conf
      lineinfile:
        dest: "/var/groupon/postgresql/data94/{{ gds_cluster }}-{{ instance }}/data/recovery.conf"
        regexp: "{{ item.regexp }}"
        line: "{{ item.line }}"
      with_items:
        - { regexp: "^primary_conninfo", line: "primary_conninfo = 'user=postgres host={{ my_crossdc_slave_ip }} port={{ gds_instances[instance].ports.postgresql_raw }} sslmode=prefer sslcompression=1'" }
        - { regexp: "^recovery_target_timeline", line: "recovery_target_timeline = 'latest'" }

    - name: Restart the instance
      shell: sv int /var/service/postgresql-{{ gds_cluster }}-{{ instance }}/

- name: Final Slave check
  gather_facts: False
  become: true
  hosts:
    - '{{ current_slave }}'
  tasks:
    - set_fact: my_master_ip={{ hostvars[current_master]['current_master_ip']['stdout'] }}
#    - debug: var=my_master_ip

    - set_fact: my_crossdc_slave_ip={{ hostvars[cross_dc_slave]['current_cross_dc_slave_ip']['stdout'] }}
#    - debug: var=my_crossdc_slave_ip

    - name: Find new slave
      command: psql -U postgres -A -t -p {{ gds_instances[instance].ports.postgresql_raw }} -c "select count(*) from pg_stat_replication where backend_start > now() - interval '5 minutes' and client_addr IN ('{{ my_master_ip }}','{{ my_crossdc_slave_ip }}')"
      register: new_slaves_exist
      until: new_slaves_exist.stdout == "2"
      retries: 300
      delay: 1


- name: Final cross dc slave check
  gather_facts: False
  become: true
  hosts:
    - '{{ cross_dc_slave }}'
  tasks:
    - set_fact: my_samedc_slave_ip={{ hostvars[same_dc_slave]['current_same_dc_slave_ip']['stdout'] }}
#    - debug: var=my_samedc_slave_ip
    - name: Find new slave
      command: psql -U postgres -A -t -p {{ gds_instances[instance].ports.postgresql_raw }} -c "select count(*) from pg_stat_replication where backend_start > now() - interval '5 minutes' and client_addr IN ('{{ my_samedc_slave_ip }}')"
      register: new_slaves_exist
      until: new_slaves_exist.stdout == "1"
      retries: 300
      delay: 1
